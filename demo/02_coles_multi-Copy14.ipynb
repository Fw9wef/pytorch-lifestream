{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ae8387-0d9d-4fc1-be77-77c5bb0d0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.nn.normalization import L2NormEncoder\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import ptls.data_load\n",
    "import ptls.data_load.datasets\n",
    "import ptls.frames\n",
    "import ptls.frames.coles\n",
    "import ptls.frames.inference_module\n",
    "import ptls.nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961141cf-63ad-44ea-9619-e89cf39cc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='multi_coles_static_adaptive_idx_7'\n",
    "EMBED_COEF = 0.05\n",
    "fold_i = 4\n",
    "gpu_n = 0\n",
    "\n",
    "df_trx_pretrain = pd.read_pickle(f'idx_data/fold_{fold_i}/df_trx_pretrain.pickle')\n",
    "df_seq_pretrain = pd.read_pickle(f'idx_data/fold_{fold_i}/df_seq_pretrain.pickle')\n",
    "df_gbm_train = pd.read_pickle(f'idx_data/fold_{fold_i}/df_gbm_train.pickle')\n",
    "df_gbm_test = pd.read_pickle(f'idx_data/fold_{fold_i}/df_gbm_test.pickle')\n",
    "\n",
    "with open(f'idx_data/fold_{fold_i}/pdp.pickle', 'rb') as f:\n",
    "    pdp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb4ca73-10cc-41d0-bc7c-e1a98ae4f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_pretrain_train, df_seq_pretrain_valid = train_test_split(\n",
    "    df_seq_pretrain, test_size=0.05, shuffle=True, random_state=42)\n",
    "len(df_seq_pretrain_train), len(df_seq_pretrain_valid)\n",
    "\n",
    "\n",
    "coles_data_module = ptls.frames.PtlsDataModule(\n",
    "    train_data=ptls.frames.coles.ColesDataset(\n",
    "        data=ptls.data_load.datasets.MemoryMapDataset(\n",
    "            df_seq_pretrain_train.to_dict(orient='records') + \n",
    "            df_trx_pretrain.to_dict(orient='records')\n",
    "        ),\n",
    "        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=200,\n",
    "        ),\n",
    "    ),\n",
    "    valid_data=ptls.frames.coles.ColesDataset(\n",
    "        data=ptls.data_load.datasets.MemoryMapDataset(\n",
    "            df_seq_pretrain_train.to_dict(orient='records')),\n",
    "        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=100,\n",
    "        ),\n",
    "    ),\n",
    "    train_batch_size=64,\n",
    "    train_num_workers=4,\n",
    "    valid_batch_size=650,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9886e-b797-4426-9fc5-ca00fe5ba105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d509c4-491c-4444-a639-8eb4ac37186c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3181db-0976-42ba-aa57-b9ebba4103c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npl_coles_module = ptls.frames.coles.CoLESModule(\\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\\n        K=4,\\n        metric='cosine',\\n    ),\\n    seq_encoder=ptls.nn.RnnSeqEncoder(\\n        trx_encoder=ptls.nn.TrxEncoder(norm_embeddings=False,\\n                                       embeddings_noise=0.003,\\n                                       embeddings={\\n                                               'weekday': {'in': 10, 'out': 8},\\n                                               'small_group': {'in': 250, 'out': 16},\\n                                               'event_time': {'in': 800, 'out': 8},\\n                                           },\\n                                       numeric_values={ \\n                                               'amount_rur': 'log',\\n                                           },\\n                                       ),\\n        \\n        input_size=33,\\n        type='gru',\\n        hidden_size=400,\\n        is_reduce_sequence=True,\\n    ),\\n    head=ptls.nn.Head(use_norm_encoder=True),\\n    loss=ptls.frames.coles.losses.ContrastiveLoss(\\n        margin=1.,\\n        sampling_strategy=ptls.frames.coles.sampling_strategies.HardNegativePairSelector(\\n          neg_count=5,\\n        ),\\n    ),\\n    optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\\n    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025)\\n)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pl_coles_module = ptls.frames.coles.CoLESModule(\n",
    "    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n",
    "        K=4,\n",
    "        metric='cosine',\n",
    "    ),\n",
    "    seq_encoder=ptls.nn.RnnSeqEncoder(\n",
    "        trx_encoder=ptls.nn.TrxEncoder(norm_embeddings=False,\n",
    "                                       embeddings_noise=0.003,\n",
    "                                       embeddings={\n",
    "                                               'weekday': {'in': 10, 'out': 8},\n",
    "                                               'small_group': {'in': 250, 'out': 16},\n",
    "                                               'event_time': {'in': 800, 'out': 8},\n",
    "                                           },\n",
    "                                       numeric_values={ \n",
    "                                               'amount_rur': 'log',\n",
    "                                           },\n",
    "                                       ),\n",
    "        \n",
    "        input_size=33,\n",
    "        type='gru',\n",
    "        hidden_size=400,\n",
    "        is_reduce_sequence=True,\n",
    "    ),\n",
    "    head=ptls.nn.Head(use_norm_encoder=True),\n",
    "    loss=ptls.frames.coles.losses.ContrastiveLoss(\n",
    "        margin=1.,\n",
    "        sampling_strategy=ptls.frames.coles.sampling_strategies.HardNegativePairSelector(\n",
    "          neg_count=5,\n",
    "        ),\n",
    "    ),\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bfc16e-ce8a-445f-8e1e-39f64ffd5879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainer = pl.Trainer(\\n    gpus=[gpu_n],\\n    max_epochs=150,\\n    enable_checkpointing=False,\\n    enable_progress_bar=True,\\n    gradient_clip_val=0.5,\\n    gradient_clip_algorithm=\"value\",\\n    track_grad_norm = 2,\\n)\\n\\npretrain_logger_version = trainer.logger.version\\nprint(f\\'pretrain_logger_version = {pretrain_logger_version}\\')\\ntrainer.fit(pl_coles_module, coles_data_module)\\n\\nfirst_model_name = \\'_\\'.join([\\'first_model\\', MODEL_NAME, str(fold_i)]) + \\'.pth\\'\\ntorch.save(pl_coles_module.seq_encoder.state_dict(), first_model_name)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "trainer = pl.Trainer(\n",
    "    gpus=[gpu_n],\n",
    "    max_epochs=150,\n",
    "    enable_checkpointing=False,\n",
    "    enable_progress_bar=True,\n",
    "    gradient_clip_val=0.5,\n",
    "    gradient_clip_algorithm=\"value\",\n",
    "    track_grad_norm = 2,\n",
    ")\n",
    "\n",
    "pretrain_logger_version = trainer.logger.version\n",
    "print(f'pretrain_logger_version = {pretrain_logger_version}')\n",
    "trainer.fit(pl_coles_module, coles_data_module)\n",
    "\n",
    "first_model_name = '_'.join(['first_model', MODEL_NAME, str(fold_i)]) + '.pth'\n",
    "torch.save(pl_coles_module.seq_encoder.state_dict(), first_model_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23683c11-a9f4-46c5-b269-37bc30c350df",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_name = '_'.join(['first_model', 'coles_first_model_idx_7', str(fold_i)]) + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bce8ad-351c-46a9-a6f4-2baf28bf5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "while first_model_name not in os.listdir():\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb947bc-91e5-4a32-baab-fd867d16fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23b3953-1832-4c95-8b55-7249a9a7c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(torch.nn.Linear(h, h), torch.nn.BatchNorm1d(h), torch.nn.ReLU(), \n",
    "                                 torch.nn.Linear(h, h), torch.nn.BatchNorm1d(h), torch.nn.ReLU())\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.net(inp) + inp\n",
    "\n",
    "\n",
    "class ClfDisc(torch.nn.Module):\n",
    "    def __init__(self, inp1=400, inp2=400, h=512):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Sequential(torch.nn.Linear(inp1, h), torch.nn.BatchNorm1d(h), torch.nn.ReLU(),\n",
    "                                     ResNet(h), ResNet(h), ResNet(h), L2NormEncoder())\n",
    "        self.b = torch.nn.Sequential(torch.nn.Linear(inp1, h), torch.nn.BatchNorm1d(h), torch.nn.ReLU(),\n",
    "                                     ResNet(h), ResNet(h), ResNet(h), L2NormEncoder())\n",
    "\n",
    "    def forward(self, domain_a, domain_b):\n",
    "        a = self.a(domain_a)\n",
    "        b = self.b(domain_b)\n",
    "        return -torch.sqrt(((a - b) ** 2).sum(axis=-1, keepdims=True))\n",
    "\n",
    "\n",
    "class IdentityDisc(torch.nn.Module):\n",
    "    def __init__(self, inp=400, h=512):\n",
    "        super().__init__()\n",
    "        self.inp = 400\n",
    "        self.h = 512\n",
    "        self.k = self.h / self.inp\n",
    "        self.register_parameter('lame', torch.nn.Parameter(torch.tensor(0.)))\n",
    "\n",
    "    def forward(self, domain_a, domain_b):\n",
    "        return ((domain_a - domain_b)**2).sum(axis=-1, keepdims=True) * self.k + 0 * self.lame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d6f5e4-cf93-45b0-90d6-eb4c07c27671",
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_loss = ptls.frames.coles.losses.ContrastiveLoss(margin=1.,\n",
    "                             sampling_strategy=ptls.frames.coles.sampling_strategies.HardNegativePairSelector(neg_count=5))\n",
    "club_loss = ptls.frames.coles.losses.CLUBLoss(log_var=-2, emb_coef=1, prob_coef=1.)\n",
    "\n",
    "\n",
    "#discriminator_model = torch.nn.Sequential(torch.nn.Linear(400, 512), torch.nn.BatchNorm1d(512), torch.nn.ReLU(), \n",
    "#                                          torch.nn.Linear(512, 512), torch.nn.BatchNorm1d(512), torch.nn.ReLU(),\n",
    "#                                          torch.nn.Linear(512, 400), ptls.nn.L2NormEncoder())\n",
    "discriminator_model = ClfDisc()\n",
    "\n",
    "seq_encoder=ptls.nn.RnnSeqEncoder(\n",
    "    trx_encoder=ptls.nn.TrxEncoder(norm_embeddings=False,\n",
    "                                   embeddings_noise=0.003,\n",
    "                                   embeddings={'weekday': {'in': 10, 'out': 8},\n",
    "                                               'small_group': {'in': 250, 'out': 16},\n",
    "                                               'event_time': {'in': 800, 'out': 8},\n",
    "                                               'index_0': {'in': 7, 'out': 8},\n",
    "                                               #'index_1': {'in': 47, 'out': 16},\n",
    "                                               #'index_2': {'in': 157, 'out': 16},\n",
    "                                              },\n",
    "                                   numeric_values={ \n",
    "                                               'amount_rur': 'log',},\n",
    "                                  ),\n",
    "    \n",
    "    input_size=41,\n",
    "    type='gru',\n",
    "    hidden_size=400,\n",
    "    is_reduce_sequence=True\n",
    ")\n",
    "\n",
    "\n",
    "pl_coles_module = ptls.frames.coles.MultiCoLESModule(\n",
    "    head=ptls.nn.Head(use_norm_encoder=True),\n",
    "    loss=coles_loss,\n",
    "    discriminator_loss=club_loss,\n",
    "    seq_encoder=seq_encoder,\n",
    "    discriminator=discriminator_model,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "    d_optimizer_partial=partial(torch.optim.Adam, lr=0.01),\n",
    "    trained_encoders=[first_model_name],\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025),\n",
    "    coles_coef=1.,\n",
    "    embed_coef=EMBED_COEF,\n",
    "    g_step_every=1,\n",
    "    ema_alpha=0.01,\n",
    "    gamma_max=0.97,\n",
    "    gamma_min=0.85,\n",
    "    delta_coef=0.0001,\n",
    "    delta_up_coef=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a38046-9dc4-4e60-840a-86d47796e93f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_logger_version = 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                    | Type            | Params\n",
      "------------------------------------------------------------\n",
      "0 | _loss                   | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder            | RnnSeqEncoder   | 542 K \n",
      "2 | _validation_metric      | BatchRecallTopK | 0     \n",
      "3 | discriminator_loss      | CLUBLoss        | 0     \n",
      "4 | trained_models          | ModuleList      | 542 K \n",
      "5 | discriminator           | ClfDisc         | 3.6 M \n",
      "6 | reference_discriminator | ClfDisc         | 3.6 M \n",
      "7 | _head                   | Head            | 0     \n",
      "------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "542 K     Non-trainable params\n",
      "8.2 M     Total params\n",
      "32.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8eb6cb5be9433daba1bc32f194f3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[gpu_n],\n",
    "    max_epochs=30, # 150,\n",
    "    enable_checkpointing=False,\n",
    "    enable_progress_bar=True,\n",
    "    track_grad_norm = 2,\n",
    ")\n",
    "pretrain_logger_version = trainer.logger.version\n",
    "print(f'pretrain_logger_version = {pretrain_logger_version}')\n",
    "trainer.fit(pl_coles_module, coles_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290fc2b-140c-4ff4-85ce-6bd598f860ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3775c8a-c95b-42f7-ac3d-31a20f7c30fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2a3809-7ec1-4843-9092-16484adc719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "inference_dl_gbm_train = torch.utils.data.DataLoader(\n",
    "    dataset=ptls.data_load.datasets.MemoryMapDataset(\n",
    "        df_gbm_train.to_dict(orient='records'),\n",
    "        i_filters=[\n",
    "            ptls.data_load.iterable_processing.ISeqLenLimit(max_seq_len=2000), \n",
    "        ],\n",
    "    ),\n",
    "    collate_fn=ptls.data_load.utils.collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=1000,\n",
    "    num_workers=12,\n",
    ")\n",
    "\n",
    "inference_dl_gbm_test = torch.utils.data.DataLoader(\n",
    "    dataset=ptls.data_load.datasets.MemoryMapDataset(\n",
    "        df_gbm_test.to_dict(orient='records'),\n",
    "        i_filters=[\n",
    "            ptls.data_load.iterable_processing.ISeqLenLimit(max_seq_len=2000), \n",
    "        ],\n",
    "    ),\n",
    "    collate_fn=ptls.data_load.utils.collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=1000,\n",
    "    num_workers=12,\n",
    ")\n",
    "\n",
    "\n",
    "inf_model = ptls.frames.inference_module.InferenceModule(\n",
    "    model=pl_coles_module, pandas_output=True, model_out_name='emb')\n",
    "\n",
    "predict_gbm_train = pl.Trainer(gpus=[gpu_n], enable_progress_bar=False, logger=None)\\\n",
    ".predict(inf_model, inference_dl_gbm_train)\n",
    "\n",
    "predict_gbm_test = pl.Trainer(gpus=[gpu_n], enable_progress_bar=False, logger=None)\\\n",
    ".predict(inf_model, inference_dl_gbm_test)\n",
    "\n",
    "predict_gbm_train = pd.concat(predict_gbm_train, axis=0)\n",
    "predict_gbm_test = pd.concat(predict_gbm_test, axis=0)\n",
    "predict_gbm_train.set_index('client_id', inplace=True)\n",
    "predict_gbm_test.set_index('client_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455043-58a1-4c34-bc2f-6ed4d22a841f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d698d7d-9f63-4381-a97d-187220f8f131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e00105-a551-4d0f-b961-e1bbbe65784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -1.386794\n",
      "[LightGBM] [Info] Start training from score -1.378326\n",
      "[LightGBM] [Info] Start training from score -1.385128\n",
      "0.606\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -1.386794\n",
      "[LightGBM] [Info] Start training from score -1.378326\n",
      "[LightGBM] [Info] Start training from score -1.385128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6113333333333333\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -1.386794\n",
      "[LightGBM] [Info] Start training from score -1.378326\n",
      "[LightGBM] [Info] Start training from score -1.385128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6081666666666666\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -1.386794\n",
      "[LightGBM] [Info] Start training from score -1.378326\n",
      "[LightGBM] [Info] Start training from score -1.385128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.6128333333333333\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204000\n",
      "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -1.386794\n",
      "[LightGBM] [Info] Start training from score -1.378326\n",
      "[LightGBM] [Info] Start training from score -1.385128\n",
      "0.6051666666666666\n"
     ]
    }
   ],
   "source": [
    "for gbm_i in range(5):\n",
    "    gbm_model = LGBMClassifier(**{\n",
    "          'n_estimators': 1000,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 4,\n",
    "          'metric': 'multi_error',\n",
    "          'learning_rate': 0.02,\n",
    "          'subsample': 0.75,\n",
    "          'subsample_freq': 1,\n",
    "          'feature_fraction': 0.75,\n",
    "          'colsample_bytree': None,\n",
    "          'max_depth': 12,\n",
    "          'lambda_l1': 1,\n",
    "          'reg_alpha': None,\n",
    "          'lambda_l2': 1,\n",
    "          'reg_lambda': None,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'min_child_samples': None,\n",
    "          'num_leaves': 50,\n",
    "          'random_state': 42+gbm_i,\n",
    "          'n_jobs': 4,\n",
    "    })\n",
    "    gbm_model.fit(predict_gbm_train.drop(columns='bins'), predict_gbm_train['bins'])\n",
    "    \n",
    "    acc = accuracy_score(\n",
    "        gbm_model.predict(predict_gbm_test.drop(columns='bins')), \n",
    "        predict_gbm_test['bins'],\n",
    "    )\n",
    "    with open('my_results_idx.log', 'at') as f:\n",
    "        print('\\t'.join([\n",
    "            MODEL_NAME,\n",
    "            f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S}',\n",
    "            f'{fold_i}',\n",
    "            'accuracy',\n",
    "            f'{acc:.4f}',\n",
    "            f'{pretrain_logger_version}',\n",
    "            'gbm_seed',\n",
    "            f'{42+gbm_i}'\n",
    "        ]), file=f)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c829fb-4c44-47aa-ab54-ed0af498c74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
