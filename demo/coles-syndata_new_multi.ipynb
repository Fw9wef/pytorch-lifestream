{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587df1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('fork')\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from ptls.data_load.datasets import SyntheticDataset, ParquetFiles, ParquetDataset\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SeqToTargetIterableDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from ptls.data_load.datasets import SyntheticDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset, ColesIterableDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head, TransformerSeqEncoder, SphereHead\n",
    "from ptls.frames.coles import CoLESModule, MultiCoLESModule\n",
    "from ptls.frames.coles.losses import CLUBLoss, MultiContrastiveLoss, MultiLoss, ContrastiveLoss\n",
    "from ptls.frames.coles.metric import MultiBatchRecallTopK, BatchAccuracy\n",
    "from ptls.frames.coles.sampling_strategies import HardNegativePairSelector\n",
    "from ptls.nn.normalization import L2NormEncoder\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from ptls.data_load.datasets import Config, MonoTargetSyntheticDatasetWriter\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fee7fc-32ed-4042-a13f-5c7f2ad15c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_n = 1\n",
    "n_models=1\n",
    "\n",
    "n_s = 8\n",
    "n_hs = 4\n",
    "seq_len = 1024\n",
    "\n",
    "a_sat = 0.\n",
    "b_sat = 1.\n",
    "noise = 0.\n",
    "\n",
    "n_states = n_s ** 2\n",
    "n_hidden_states = n_hs ** 2\n",
    "\n",
    "name = \"corr_new_data_\"+ \"_\".join([str(x) for x in [a_sat, b_sat, noise]])\n",
    "path_to_data = \"syndata/\" + name + \"/\"\n",
    "noise_level = name\n",
    "path_to_log = name + \".txt\"\n",
    "\n",
    "#with open(path_to_log, \"w\") as f:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62c3ed2-d9b2-49ca-a50f-2a240a223c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_config(noise):\n",
    "    chain_confs = {\n",
    "        \"A\": (n_hs, 4, noise),\n",
    "        \"B\": (n_s, 16, 0),\n",
    "    }\n",
    "\n",
    "    state_from = [\"A\"]\n",
    "    state_to = [\"B\"]\n",
    "\n",
    "    labeling_conf = {\n",
    "        0: {\"A\": a_sat,\n",
    "            \"B\": b_sat}\n",
    "    }\n",
    "\n",
    "    config = Config(chain_confs, state_from, state_to, labeling_conf)\n",
    "    return config\n",
    "\n",
    "\n",
    "config = get_config(noise)\n",
    "writer = MonoTargetSyntheticDatasetWriter(config, path=path_to_data, seq_len=seq_len,\n",
    "                                          n_train_files=250, n_eval_files=50, n_test_files=0,\n",
    "                                          train_per_file=256*4, eval_per_file=256*4, test_per_file=256*4,\n",
    "                                          save_config_name=\"corr_config\", save=False, load=True, n_procs=4)\n",
    "#writer.write_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c51197e-6f9b-47cc-bdee-d4e502153223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sup_model(model, sup_data, exp_name):\n",
    "    model.to('cuda:' + str(gpu_n))\n",
    "    \n",
    "    yy_pred_eval, yy_eval = list(), list()\n",
    "    dl = iter(sup_data.val_dataloader())\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy_eval.append(y.numpy())\n",
    "            y_pred = model(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy()\n",
    "            yy_pred_eval.append(y_pred)\n",
    "\n",
    "    yy_pred_eval = np.concatenate(yy_pred_eval, axis=0)[:, 1]\n",
    "    yy_eval = np.concatenate(yy_eval, axis=0)\n",
    "\n",
    "    score = roc_auc_score(yy_eval, yy_pred_eval)\n",
    "\n",
    "    with open(path_to_log, \"a\") as f:\n",
    "        f.writelines([f'{exp_name},{noise_level},{score}\\n'])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724e2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_data(path):\n",
    "    train_files = ParquetFiles(os.path.join(path, \"train\"))\n",
    "    train_dataset = ParquetDataset(train_files, shuffle_files=True)\n",
    "    eval_files = ParquetFiles(os.path.join(path, \"eval\"))\n",
    "    eval_dataset = ParquetDataset(eval_files, shuffle_files=True)\n",
    "    test_files = ParquetFiles(os.path.join(path, \"test\"))\n",
    "    test_dataset = ParquetDataset(test_files, shuffle_files=True)\n",
    "    \n",
    "    sup_data = PtlsDataModule(\n",
    "        train_data=SeqToTargetIterableDataset(train_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        valid_data=SeqToTargetIterableDataset(eval_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        #test_data=SeqToTargetIterableDataset(test_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        train_batch_size=512,\n",
    "        valid_batch_size=512,\n",
    "        #test_batch_size=256,\n",
    "        train_num_workers=4,\n",
    "        valid_num_workers=4,\n",
    "        #test_num_workers=4\n",
    "    )\n",
    "    return sup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e504eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_model():\n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                'B': {'in': n_states, 'out': 16},\n",
    "                'A': {'in': n_hidden_states, 'out': 16},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=256,\n",
    "        type='lstm',\n",
    "    )\n",
    "\n",
    "    sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=2),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.Accuracy(),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.9),\n",
    "    )\n",
    "    return sup_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e34144",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"early_fusion_supervised_\" + str(noise_level))\n",
    "'''\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=13,\n",
    "    gpus=[gpu_n],\n",
    "    enable_progress_bar=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "'''\n",
    "sup_data = get_sup_data(path_to_data)\n",
    "#sup_model = get_sup_model()\n",
    "\n",
    "#trainer.fit(sup_model, sup_data)\n",
    "#clear_output()\n",
    "\n",
    "#test_sup_model(sup_model, sup_data, \"early_fusion_supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b01d-b336-425b-9154-80b3cc505b5d",
   "metadata": {},
   "source": [
    "# States Only Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf66856-6b39-493b-aed2-d6a86b7f0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_sup_model():\n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                'B': {'in': n_states, 'out': 16},\n",
    "                #'A': {'in': n_hidden_states, 'out': 16},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=256,\n",
    "        type='lstm',\n",
    "    )\n",
    "\n",
    "    sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=2),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.Accuracy(),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.9),\n",
    "    )\n",
    "    return sup_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce97274c-1359-45dc-bf17-a6f467eafc9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainer = pl.Trainer(\\n    max_epochs=13,\\n    gpus=[gpu_n],\\n    enable_progress_bar=False,\\n    logger=tb_logger\\n)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"states_only_supervised_\" + str(noise_level))\n",
    "'''\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=13,\n",
    "    gpus=[gpu_n],\n",
    "    enable_progress_bar=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "'''\n",
    "#sup_data = get_sup_data(path_to_data)\n",
    "#sup_model = get_states_sup_model()\n",
    "\n",
    "#trainer.fit(sup_model, sup_data)\n",
    "#clear_output()\n",
    "\n",
    "#test_sup_model(sup_model, sup_data, \"states_only_supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054e313-8675-4c19-a2af-187c10ddd7fe",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673884aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embed_model(model, sup_data, exp_name):\n",
    "    model.to('cuda:' + str(gpu_n))\n",
    "    \n",
    "    xx, yy = list(), list()\n",
    "    dl = iter(sup_data.train_dataloader())\n",
    "    for batch in dl:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy.append(y.numpy())\n",
    "\n",
    "            x_list = list()\n",
    "            if model.trained_models is not None:\n",
    "                x_list.extend([m(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy() for m in model.trained_models])\n",
    "            x_list.append(model(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy())\n",
    "            \n",
    "            x = np.concatenate(x_list, axis=-1)\n",
    "            xx.append(x)\n",
    "\n",
    "    xx = np.concatenate(xx, axis=0)\n",
    "    yy = np.concatenate(yy, axis=0)\n",
    "    \n",
    "    xx_eval, yy_eval = list(), list()\n",
    "    dl = iter(sup_data.val_dataloader())\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy_eval.append(y.numpy())\n",
    "            \n",
    "            x_list = list()\n",
    "            if model.trained_models is not None:\n",
    "                x_list.extend([m(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy() for m in model.trained_models])\n",
    "            x_list.append(model(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy())\n",
    "            \n",
    "            x = np.concatenate(x_list, axis=-1)\n",
    "            xx_eval.append(x)\n",
    "\n",
    "    xx_eval = np.concatenate(xx_eval, axis=0)\n",
    "    yy_eval = np.concatenate(yy_eval, axis=0)\n",
    "\n",
    "    n = int(xx_eval.shape[0]/2)\n",
    "    xx_test = xx_eval[:n]\n",
    "    yy_test = yy_eval[:n]\n",
    "\n",
    "    xx_eval = xx_eval[n:]\n",
    "    yy_eval = yy_eval[n:]\n",
    "    \n",
    "    \n",
    "    clf = LGBMClassifier(max_depth=-1)\n",
    "    clf.fit(xx, yy, eval_set=(xx_eval, yy_eval), eval_metric=\"auc\")\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx)[:,1]\n",
    "    train_score = roc_auc_score(yy, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_eval)[:,1]\n",
    "    eval_score = roc_auc_score(yy_eval, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_test)[:,1]\n",
    "    test_score = roc_auc_score(yy_test, y_pred)\n",
    "\n",
    "    with open(path_to_log, \"a\") as f:\n",
    "        f.writelines([f'{exp_name},{noise_level},{test_score}\\n'])\n",
    "    \n",
    "    return train_score, eval_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "624065bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coles_data(path):\n",
    "    train_files = ParquetFiles(os.path.join(path, \"train\"))\n",
    "    train_dataset = ParquetDataset(train_files, shuffle_files=True)\n",
    "    eval_files = ParquetFiles(os.path.join(path, \"eval\"))\n",
    "    eval_dataset = ParquetDataset(eval_files, shuffle_files=True)\n",
    "    test_files = ParquetFiles(os.path.join(path, \"test\"))\n",
    "    test_dataset = ParquetDataset(test_files, shuffle_files=True)\n",
    "\n",
    "    train_dl = PtlsDataModule(\n",
    "        train_data=ColesIterableDataset(\n",
    "            train_dataset,\n",
    "            splitter=SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=70,\n",
    "                cnt_max=100,\n",
    "            ),\n",
    "        ),\n",
    "        valid_data=ColesIterableDataset(\n",
    "            eval_dataset,\n",
    "            splitter=SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=70,\n",
    "                cnt_max=100,),\n",
    "        ),\n",
    "        train_num_workers=4,\n",
    "        train_batch_size=512,\n",
    "        valid_num_workers=4,\n",
    "        valid_batch_size=512,\n",
    "    )\n",
    "    \n",
    "    return train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988c508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coles_model():\n",
    "    coles_loss = ContrastiveLoss(margin=1,\n",
    "                                 sampling_strategy=HardNegativePairSelector(neg_count=5))\n",
    "    club_loss = CLUBLoss(log_var=-2, emb_coef=1, prob_coef=1.)\n",
    "    metric = MultiBatchRecallTopK(n=2,\n",
    "                                  K=4,\n",
    "                                  metric='cosine',)\n",
    "\n",
    "    discriminator_model = torch.nn.Sequential(torch.nn.Linear(128, 512), torch.nn.BatchNorm1d(512), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(512, 512), torch.nn.BatchNorm1d(512), torch.nn.ReLU(),\n",
    "                                              torch.nn.Linear(512, 128), L2NormEncoder())\n",
    "    \n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                'B': {'in': n_states, 'out': 16},\n",
    "                'A': {'in': n_hidden_states, 'out': 16},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=128,\n",
    "        type='lstm',\n",
    "    )\n",
    "    \n",
    "    model = MultiCoLESModule(\n",
    "        head=Head(use_norm_encoder=True),\n",
    "        #validation_metric = metric,\n",
    "        loss=coles_loss,\n",
    "        discriminator_loss=club_loss,\n",
    "        seq_encoder=seq_encoder,\n",
    "        discriminator=discriminator_model,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        d_optimizer_partial=partial(torch.optim.Adam, lr=0.01),\n",
    "        trained_encoders=['first_model.pth'],\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    "        coles_coef=1.,\n",
    "        embed_coef=0.011,\n",
    "        g_step_every=1\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fdbb67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 128000, number of negative: 128000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65280\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6643004255981445, 0.6079705287590461, 0.6174298368513145)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"multi_early_fusion_coles_\" + str(noise_level))\n",
    "\n",
    "coles_dl = get_coles_data(path_to_data)\n",
    "coles_model = get_coles_model()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=[gpu_n],\n",
    "    enable_progress_bar=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "trainer.fit(coles_model, coles_dl)\n",
    "clear_output()\n",
    "\n",
    "test_embed_model(coles_model, sup_data, \"multi_early_fusion_coles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97ea19c-f9f7-4d3b-8052-06ed2ce4d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 128000, number of negative: 128000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65280\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.664540282409668, 0.6125706067170339, 0.6167011075980888)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed_model(coles_model, sup_data, \"multi_early_fusion_coles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f09f57b-086d-4dbe-b217-429718b1c502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 128000, number of negative: 128000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.327252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65280\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6646085024414061, 0.6151257985962694, 0.6139756519995754)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed_model(coles_model, sup_data, \"multi_early_fusion_coles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9633678c-93e8-47d4-b322-4c57ee75d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 128000, number of negative: 128000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.511083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65280\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 256\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6646171783447266, 0.6149339119727834, 0.6136042424911665)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed_model(coles_model, sup_data, \"multi_early_fusion_coles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561297e-0cc3-424a-86ac-50443895b0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea64899-6035-4c9e-88d2-4b1a05a6a7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7a060-ad72-4db0-9ff9-cf08a3bc8861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69ddd62-09c1-4612-98fd-2649b8d048b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_model.embed_coef = 0.\n",
    "coles_model.coles_coef = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca441ea9-4070-486b-a76e-55558ee365e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 84.4 K\n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | discriminator_loss | CLUBLoss        | 0     \n",
      "4 | trained_models     | ModuleList      | 84.4 K\n",
      "5 | discriminator      | Sequential      | 396 K \n",
      "6 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "480 K     Trainable params\n",
      "84.4 K    Non-trainable params\n",
      "565 K     Total params\n",
      "2.260     Total estimated model params size (MB)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8bdafe6cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8bdafe6cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8bdafe6cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8bdafe6cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionErrorcan only test a child process: \n"
     ]
    }
   ],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"multi_early_fusion_coles_\" + str(noise_level))\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=[gpu_n],\n",
    "    enable_progress_bar=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "trainer.fit(coles_model, coles_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0a6fa3-aab6-4ade-b196-a42b4dbe87e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fb8931835b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7fb8931835b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_embed_model(coles_model, sup_data, \"multi_early_fusion_coles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373830f0-8d25-4dfb-8d77-f898e30e5f50",
   "metadata": {},
   "source": [
    "# States Only Coles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63e399a-fa34-4f67-a093-f3d3db87f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coles_states_model():\n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                'B': {'in': n_states, 'out': 16},\n",
    "                #'A': {'in': n_hidden_states, 'out': 16},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=256,\n",
    "        type='lstm',\n",
    "    )\n",
    "    \n",
    "    model = CoLESModule(\n",
    "        seq_encoder=seq_encoder,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4dff35a-5c6a-4a28-bf3a-da8512fe5036",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.55528545 -0.06221164  0.16263163 ... -0.20286767 -0.3722022\n  0.6936094 ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model_s, coles_dl)\n\u001b[1;32m     13\u001b[0m clear_output()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtest_embed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstates_only_coles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m, in \u001b[0;36mtest_embed_model\u001b[0;34m(model, sup_data, exp_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m yy_eval \u001b[38;5;241m=\u001b[39m yy_eval[n:]\n\u001b[1;32m     40\u001b[0m clf \u001b[38;5;241m=\u001b[39m LGBMClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy_eval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(xx)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     44\u001b[0m train_score \u001b[38;5;241m=\u001b[39m roc_auc_score(yy, y_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:813\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    810\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [metric \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m--> 813\u001b[0m     _X, _y \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMCheckXY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.55528545 -0.06221164  0.16263163 ... -0.20286767 -0.3722022\n  0.6936094 ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"states_only_coles_\" + str(noise_level))\n",
    "\n",
    "#coles_dl = get_coles_data(path_to_data)\n",
    "model_s = get_coles_states_model()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=[gpu_n],\n",
    "    enable_progress_bar=False,\n",
    "    logger=tb_logger\n",
    ")\n",
    "trainer.fit(model_s, coles_dl)\n",
    "clear_output()\n",
    "\n",
    "test_embed_model(model_s, sup_data, \"states_only_coles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25326f-dd0a-47c2-9288-c10b4cceadaf",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8af80f-0c7f-4fde-8426-80b8bac26642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_late_embed_model(models, sup_data, exp_name):\n",
    "    for m in models:\n",
    "        m.to('cuda:' + str(gpu_n))\n",
    "    \n",
    "    xx, yy = list(), list()\n",
    "    dl = iter(sup_data.train_dataloader())\n",
    "    for batch in dl:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy.append(y.numpy())\n",
    "            xi = list()\n",
    "            for m in models:\n",
    "                x_m = m(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy()\n",
    "                xi.append(x_m)\n",
    "            x = np.concatenate(xi, axis=-1)\n",
    "            xx.append(x)\n",
    "\n",
    "    xx = np.concatenate(xx, axis=0)\n",
    "    yy = np.concatenate(yy, axis=0)\n",
    "    \n",
    "    xx_eval, yy_eval = list(), list()\n",
    "    dl = iter(sup_data.val_dataloader())\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy_eval.append(y.numpy())\n",
    "            xi = list()\n",
    "            for m in models:\n",
    "                x_m = m(x.to('cuda:' + str(gpu_n))).detach().cpu().numpy()\n",
    "                xi.append(x_m)\n",
    "            x = np.concatenate(xi, axis=-1)\n",
    "            xx_eval.append(x)\n",
    "\n",
    "    xx_eval = np.concatenate(xx_eval, axis=0)\n",
    "    yy_eval = np.concatenate(yy_eval, axis=0)\n",
    "\n",
    "    n = int(xx_eval.shape[0]/2)\n",
    "    xx_test = xx_eval[:n]\n",
    "    yy_test = yy_eval[:n]\n",
    "\n",
    "    xx_eval = xx_eval[n:]\n",
    "    yy_eval = yy_eval[n:]\n",
    "    \n",
    "    \n",
    "    clf = LGBMClassifier(max_depth=-1)\n",
    "    clf.fit(xx, yy, eval_set=(xx_eval, yy_eval), eval_metric=\"auc\")\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx)[:,1]\n",
    "    train_score = roc_auc_score(yy, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_eval)[:,1]\n",
    "    eval_score = roc_auc_score(yy_eval, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_test)[:,1]\n",
    "    test_score = roc_auc_score(yy_test, y_pred)\n",
    "\n",
    "    with open(path_to_log, \"a\") as f:\n",
    "        f.writelines([f'{exp_name},{noise_level},{test_score}\\n'])\n",
    "    \n",
    "    return train_score, eval_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f1f49-0389-4c30-81c1-177527905ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h_coles_models(letter, nn):\n",
    "    seq_encoder_h = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                letter: {'in': nn, 'out': 16},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=256,\n",
    "        type='lstm',\n",
    "    )\n",
    "    \n",
    "    model_h = CoLESModule(\n",
    "        seq_encoder=seq_encoder_h,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    "    )\n",
    "    return model_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8fd01-0026-49a6-bb7e-10841bfdb54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unimodal_models = [model_s]\n",
    "for l, ni in zip(['A'], [n_hidden_states]):\n",
    "    tb_logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"h_states_only_coles_\" + str(noise_level) + \"_modality_\" + l)\n",
    "    model_h = get_h_coles_models(l, ni)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        gpus=[gpu_n],\n",
    "        enable_progress_bar=False,\n",
    "        logger=tb_logger\n",
    "    )\n",
    "    trainer.fit(model_h, coles_dl)\n",
    "    clear_output()\n",
    "    unimodal_models.append(model_h)\n",
    "\n",
    "test_late_embed_model(unimodal_models, sup_data, \"late_fusion_coles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1fc20-d65b-4adf-ab49-5cd75696a88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23de8e-c30f-4102-8262-30240b57b0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b7e3c-4ca8-47fb-8c2e-73c2378cbd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101bbed-479e-47b1-8536-e8b6f19cd7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348e43b-a931-4968-942d-4958dd5c9e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6875d18-3fe1-41f0-a80e-c28833640575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa95278-6a8e-4073-9de2-f30015aee814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac60f0-cc53-4d30-8734-4cb964c20a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0396e93-33c1-4349-b6e2-31891bf41470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise1 = (0.8007202911224365, 0.783103692626953, 0.780410511779785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509bfe9-b978-43ec-8ca6-b1a95f868c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise05 = (0.9408758544464111, 0.9335008178710937, 0.9345132614135743)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca0d1c-86c6-4b53-aa56-d1125a9ee451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise02 = (0.9177455666351317, 0.9057953903198244, 0.9047988479614257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd082f5-7333-47bf-bcef-b8788e9227e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise0 = (0.9709027706604004, 0.9667222106933593, 0.9655987045288088)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e153ad723e521bdc1aff37b3bab9b1f3df31355f5a727a9b9eb7d0282ae9ca8c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ee6696e36a496fb14601e1c68db4d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "0ca97f55cd3d4437a1b1b074c908c230": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26137948bd8f45429b7893dc09a75069": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26952339137e436eb5ce6961037effbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "364d6da46fa8437c996fd4f255f72698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37640538cd7c42989bfe6f34813a9319": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "489653f34e424b4a8d1693feac4301bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e33f33225f004815ae295a2b9f453883",
       "placeholder": "​",
       "style": "IPY_MODEL_26952339137e436eb5ce6961037effbe",
       "value": "Epoch 14: 100%"
      }
     },
     "60c687724a2a4c9a80a1a58c7a218bbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "621f6072336e40618ab6adae38e1e762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "70b148cd72e145038118fea79ff32c54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8afe3d3475684582a8d0e8b673fcad49",
       "placeholder": "​",
       "style": "IPY_MODEL_748d27490e9148219c8f188194a8b604",
       "value": "Predicting: "
      }
     },
     "71469a60dd8e4b74a97eb7c27e3aaa4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a080e7d5d5d5454aaa5aec47ab11b2f7",
        "IPY_MODEL_e79e92771c444f9fabb37c2dc304aafc",
        "IPY_MODEL_93d164c36d7146058ae0b9d8d475b06d"
       ],
       "layout": "IPY_MODEL_8831196896a64181b02a5ad0d22e0dd8"
      }
     },
     "748d27490e9148219c8f188194a8b604": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7c9829f7a9b847fdb5aeadf917a8fd7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "84559c5ef59c4ec68695403555d74c81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70b148cd72e145038118fea79ff32c54",
        "IPY_MODEL_8ccfd768f9ec462186047f88089f9a01",
        "IPY_MODEL_f4559629cb4e4f22b2cb2b1a4198c374"
       ],
       "layout": "IPY_MODEL_01ee6696e36a496fb14601e1c68db4d7"
      }
     },
     "8831196896a64181b02a5ad0d22e0dd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "8afe3d3475684582a8d0e8b673fcad49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ccfd768f9ec462186047f88089f9a01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9bab642e75ac41e29b049d13299c709c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_caa6bc12efc24d27b2a589f722bb8dcd",
       "value": 1
      }
     },
     "93d164c36d7146058ae0b9d8d475b06d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fba40d205bf7433baad90f9e567710e8",
       "placeholder": "​",
       "style": "IPY_MODEL_621f6072336e40618ab6adae38e1e762",
       "value": " 118/? [00:03&lt;00:00,  6.30it/s]"
      }
     },
     "9bab642e75ac41e29b049d13299c709c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a080e7d5d5d5454aaa5aec47ab11b2f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ca97f55cd3d4437a1b1b074c908c230",
       "placeholder": "​",
       "style": "IPY_MODEL_7c9829f7a9b847fdb5aeadf917a8fd7f",
       "value": "Predicting: "
      }
     },
     "aacec0ffb61e47c188f42f5d4ee93d07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_489653f34e424b4a8d1693feac4301bd",
        "IPY_MODEL_cc2169b121624ce490b28642b260ee68",
        "IPY_MODEL_de9674f610a04a50a662d37cd7a0fe98"
       ],
       "layout": "IPY_MODEL_60c687724a2a4c9a80a1a58c7a218bbc"
      }
     },
     "b26ad2fd0b2245d899312ce0ebd50f40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c1353e5ca7c64b2183ce2533b240acd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c9ded1ea494a476cbc5286e310d9a989": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "caa6bc12efc24d27b2a589f722bb8dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc2169b121624ce490b28642b260ee68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc7588a078fe43a2a0838cbee8349163",
       "max": 94,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b26ad2fd0b2245d899312ce0ebd50f40",
       "value": 94
      }
     },
     "cc7588a078fe43a2a0838cbee8349163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de9674f610a04a50a662d37cd7a0fe98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_37640538cd7c42989bfe6f34813a9319",
       "placeholder": "​",
       "style": "IPY_MODEL_c1353e5ca7c64b2183ce2533b240acd4",
       "value": " 94/94 [00:44&lt;00:00,  2.10it/s, loss=373, v_num=9, seq_len=113.0]"
      }
     },
     "e33f33225f004815ae295a2b9f453883": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e79e92771c444f9fabb37c2dc304aafc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9ded1ea494a476cbc5286e310d9a989",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_364d6da46fa8437c996fd4f255f72698",
       "value": 1
      }
     },
     "ecea7cc60e854a51bb8d5b1498235515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4559629cb4e4f22b2cb2b1a4198c374": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecea7cc60e854a51bb8d5b1498235515",
       "placeholder": "​",
       "style": "IPY_MODEL_26137948bd8f45429b7893dc09a75069",
       "value": " 188/? [00:15&lt;00:00,  6.24it/s]"
      }
     },
     "fba40d205bf7433baad90f9e567710e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
