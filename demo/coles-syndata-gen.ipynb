{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587df1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 02:04:41.705765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# import logging\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from ptls.data_load.datasets import SyntheticDataset, ParquetFiles, ParquetDataset\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SeqToTargetIterableDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from ptls.data_load.datasets import SyntheticDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head\n",
    "from ptls.frames.coles import CoLESModule\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd9d0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import CategoryFeature, ConstFeature, State, HMM\n",
    "from ptls.data_load.datasets import SquareSampler, SphereSampler, PlaneClassAssigner, TransitionTensorGenerator\n",
    "\n",
    "\n",
    "n_states = 8\n",
    "n_hidden_states = 4\n",
    "hidden_state_c = 0.7\n",
    "sphere_r = 16\n",
    "hidden_sphere_r = 4\n",
    "delta_shift = None\n",
    "use_pairs_to_states = True\n",
    "\n",
    "\n",
    "def get_state_features(const_p, beta_a, beta_b, c_value=None):\n",
    "    feats = {\n",
    "        \"s_feat_1\": ConstFeature(value = c_value),\n",
    "        #\"s_feat_2\": CategoryFeature(n=10, dist_type='const', dist_args={'p': const_p}),\n",
    "        #\"s_feat_3\": CategoryFeature(n=20, dist_type='beta', dist_args={'a': beta_a, 'b': beta_b}),\n",
    "        \n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "def get_h_state_features(const_p, beta_a, beta_b, c_value=None):\n",
    "    feats = {\n",
    "        \"h_feat_1\": ConstFeature(value = c_value),\n",
    "        #\"h_feat_1\": CategoryFeature(n=20, dist_type='beta', dist_args={'a': beta_a, 'b': beta_b}),\n",
    "        #\"h_feat_2\": CategoryFeature(n=10, dist_type='const', dist_args={'p': const_p}),\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "def gen_a_b(min=1, max=50):\n",
    "    a = np.random.randint(min, max)\n",
    "    if np.random.rand()>=0.5:\n",
    "        mult = 0.8 + 0.4 * np.random.rand()\n",
    "        b = int(a * mult)\n",
    "        if b < 1:\n",
    "            b = 1\n",
    "    else:\n",
    "        b = np.random.randint(min, max)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def gen_p(n, drop_percentile=30):\n",
    "    p = np.random.randn(n)\n",
    "    p = np.exp(p)/np.sum(np.exp(p))\n",
    "    v = np.percentile(p, drop_percentile)\n",
    "    p = np.where(p>=v, p, 0)\n",
    "    p = p/p.sum()\n",
    "    return p\n",
    "\n",
    "\n",
    "states = [\n",
    "    State(get_state_features(gen_p(10), *gen_a_b(), c_value=i), ind=i) for i in range(n_states)\n",
    "]\n",
    "\n",
    "\n",
    "hidden_states = [\n",
    "    State(get_h_state_features(gen_p(10), *gen_a_b(), c_value=i), ind=i) for i in range(n_hidden_states)\n",
    "]\n",
    "\n",
    "\n",
    "hidden_state_new = (1 - hidden_state_c) / (n_hidden_states - 1)\n",
    "hidden_state_transition_matrix = np.eye(n_hidden_states) * (hidden_state_c - hidden_state_new)\n",
    "hidden_state_transition_matrix += np.ones((n_hidden_states, n_hidden_states)) * hidden_state_new\n",
    "default_hidden_state_transition_matrix = hidden_state_transition_matrix\n",
    "\n",
    "\n",
    "def sample_h_mtx(n):\n",
    "    sampler = SphereSampler(n_hidden_states)\n",
    "    h_mtx = sampler.sample(n, to_matrix=False)\n",
    "    h_mtx = h_mtx / np.sqrt((h_mtx**2).sum(axis=-1, keepdims=True)) * hidden_sphere_r\n",
    "    h_mtx = h_mtx.reshape(h_mtx.shape[0], n_hidden_states, n_hidden_states)\n",
    "    h_mtx = np.exp(h_mtx)/np.exp(h_mtx).sum(axis=-1, keepdims=True)\n",
    "    return list(h_mtx)\n",
    "\n",
    "\n",
    "def get_datasets(n=10000, n_train=5000, n_eval=2000, n_test=3000, noise=0., delta_shift=10, assigner=None):\n",
    "    n_train, n_eval, n_test, n = int(n_train), int(n_eval), int(n_test), int(n)\n",
    "    assert sum([n_train, n_eval, n_test]) == n\n",
    "\n",
    "    hidden_state_transition_matrix = sample_h_mtx(n)\n",
    "    noise_hidden_state_transition_matrix = sample_h_mtx(n)\n",
    "    \n",
    "    sampler = SphereSampler(n_states)\n",
    "        \n",
    "    tensor_gen = TransitionTensorGenerator(sampler, assigner, n_hidden_states)\n",
    "    pos_tensors, neg_tensors = tensor_gen.gen_tensors(int(n), soft_norm=True, sphere_norm=True, sphere_r=sphere_r)\n",
    "\n",
    "\n",
    "    get_hmm = partial(HMM, states=states, hidden_states=hidden_states, noise=noise)\n",
    "\n",
    "\n",
    "    train_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[:n_train],\n",
    "                             hidden_state_transition_matrix=hidden_state_transition_matrix[:n_train],\n",
    "                             noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[:n_train])\n",
    "    train_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[:n_train],\n",
    "                             hidden_state_transition_matrix=hidden_state_transition_matrix[:n_train],\n",
    "                             noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[:n_train])\n",
    "\n",
    "\n",
    "    valid_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[n_train:n_eval+n_train],\n",
    "                             hidden_state_transition_matrix=hidden_state_transition_matrix[n_train:n_eval+n_train],\n",
    "                             noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[n_train:n_eval+n_train])\n",
    "    valid_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[n_train:n_eval+n_train],\n",
    "                             hidden_state_transition_matrix=hidden_state_transition_matrix[n_train:n_eval+n_train],\n",
    "                             noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[n_train:n_eval+n_train])\n",
    "\n",
    "\n",
    "    test_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[n_eval+n_train:],\n",
    "                            hidden_state_transition_matrix=hidden_state_transition_matrix[n_eval+n_train:],\n",
    "                            noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[n_eval+n_train:])\n",
    "    test_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[n_eval+n_train:],\n",
    "                            hidden_state_transition_matrix=hidden_state_transition_matrix[n_eval+n_train:],\n",
    "                            noise_hidden_state_transition_matrix=noise_hidden_state_transition_matrix[n_eval+n_train:])\n",
    "\n",
    "\n",
    "    dataset_train = SyntheticDataset([train_pos_hmms, train_neg_hmms], seq_len=512)\n",
    "    dataset_valid = SyntheticDataset([valid_pos_hmms, valid_neg_hmms], seq_len=512)\n",
    "    dataset_test = SyntheticDataset([test_pos_hmms, test_neg_hmms], seq_len=512)\n",
    "    \n",
    "    return dataset_train, dataset_valid, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83455e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_datamodule(noise, n_train=5000, n_eval=2000, n_test=3000, assigner=None):\n",
    "    n = n_train + n_eval + n_test\n",
    "    \n",
    "    dataset_train, dataset_valid, dataset_test = get_datasets(n=n, n_train=n_train, n_eval=n_eval,\n",
    "                                                              n_test=n_test, noise=noise, assigner=assigner)\n",
    "\n",
    "    sup_data = PtlsDataModule(\n",
    "        train_data=SeqToTargetDataset(dataset_train, target_col_name='class_label', target_dtype=torch.long),\n",
    "        valid_data=SeqToTargetDataset(dataset_valid, target_col_name='class_label', target_dtype=torch.long),\n",
    "        test_data=SeqToTargetDataset(dataset_test, target_col_name='class_label', target_dtype=torch.long),\n",
    "        train_batch_size=256,\n",
    "        valid_batch_size=256,\n",
    "        test_batch_size=256,\n",
    "        train_num_workers=16,\n",
    "        valid_num_workers=16,\n",
    "        test_num_workers=16\n",
    "    )\n",
    "    return sup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f1eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_to_states_tensor = np.arange(n_states * n_states).reshape(n_states, n_states)\n",
    "h_pairs_to_states_tensor = np.arange(n_hidden_states * n_hidden_states).reshape(n_hidden_states, n_hidden_states)\n",
    "\n",
    "\n",
    "def pairs_to_states(s):\n",
    "    return pairs_to_states_tensor[s[:-1], s[1:]]\n",
    "\n",
    "\n",
    "def h_pairs_to_states(s):\n",
    "    return h_pairs_to_states_tensor[s[:-1], s[1:]]\n",
    "\n",
    "\n",
    "def trunc_h_states(h):\n",
    "    return h[:-1]\n",
    "\n",
    "\n",
    "def trunc_t(t):\n",
    "    return t[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be702dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(main_folder, assigner, noise=0.,\n",
    "                  train_num_files=200, eval_num_files=100, test_num_files=100,\n",
    "                  n_train=256*10, n_eval=256*10, n_test=256*10):\n",
    "    \n",
    "    train_folder = os.path.join(main_folder, \"train\")\n",
    "    eval_folder = os.path.join(main_folder, \"eval\")\n",
    "    test_folder = os.path.join(main_folder, \"test\")\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(eval_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    for fn in tqdm(range(max(train_num_files, eval_num_files, test_num_files))):\n",
    "        data = get_sup_datamodule(noise, n_train, n_eval, n_test, assigner=assigner)\n",
    "        \n",
    "        if fn < train_num_files:\n",
    "            df = defaultdict(list)\n",
    "            for i, batch in enumerate(data.train_dataloader()):\n",
    "                x, y = batch\n",
    "                x_d = x.payload\n",
    "                for k in x_d:\n",
    "                    df[k].extend(x_d[k].int().tolist())\n",
    "                df['class_label'].extend(y.int().tolist())\n",
    "            df = pd.DataFrame(df)\n",
    "            \n",
    "            if use_pairs_to_states:\n",
    "                df[\"s_feat_1\"] = df[\"s_feat_1\"].map(pairs_to_states)\n",
    "                df[\"h_feat_1\"] = df[\"h_feat_1\"].map(h_pairs_to_states)\n",
    "                df[\"event_time\"] = df[\"event_time\"].map(trunc_t)\n",
    "            \n",
    "            df.to_parquet(os.path.join(train_folder, \"train_\"+str(fn)+\".parquet\"))\n",
    "        \n",
    "        \n",
    "        if fn < eval_num_files:\n",
    "            df = defaultdict(list)\n",
    "            for i, batch in enumerate(data.val_dataloader()):\n",
    "                x, y = batch\n",
    "                x_d = x.payload\n",
    "                for k in x_d:\n",
    "                    df[k].extend(x_d[k].int().tolist())\n",
    "                df['class_label'].extend(y.int().tolist())\n",
    "            df = pd.DataFrame(df)\n",
    "            \n",
    "            if use_pairs_to_states:\n",
    "                df[\"s_feat_1\"] = df[\"s_feat_1\"].map(pairs_to_states)\n",
    "                df[\"h_feat_1\"] = df[\"h_feat_1\"].map(h_pairs_to_states)\n",
    "                df[\"event_time\"] = df[\"event_time\"].map(trunc_t)\n",
    "            \n",
    "            df.to_parquet(os.path.join(eval_folder, \"eval_\"+str(fn)+\".parquet\"))\n",
    "        \n",
    "        \n",
    "        if fn < test_num_files:\n",
    "            df = defaultdict(list)\n",
    "            for i, batch in enumerate(data.test_dataloader()):\n",
    "                x, y = batch\n",
    "                x_d = x.payload\n",
    "                for k in x_d:\n",
    "                    df[k].extend(x_d[k].int().tolist())\n",
    "                df['class_label'].extend(y.int().tolist())\n",
    "            df = pd.DataFrame(df)\n",
    "            \n",
    "            if use_pairs_to_states:\n",
    "                df[\"s_feat_1\"] = df[\"s_feat_1\"].map(pairs_to_states)\n",
    "                df[\"h_feat_1\"] = df[\"h_feat_1\"].map(h_pairs_to_states)\n",
    "                df[\"event_time\"] = df[\"event_time\"].map(trunc_t)\n",
    "            \n",
    "            df.to_parquet(os.path.join(test_folder, \"test_\"+str(fn)+\".parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493534c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "assigner = PlaneClassAssigner(n_states, n_hidden_states, delta_shift=delta_shift)\n",
    "assigner.set_random_vector()\n",
    "\n",
    "with open(\"assigner.pickle\", \"wb\") as f:\n",
    "    pickle.dump(assigner, f)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef35c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "with open(\"states.pickle\", \"wb\") as f:\n",
    "    pickle.dump(states, f)\n",
    "\n",
    "with open(\"hidden_states.pickle\", \"wb\") as f:\n",
    "    pickle.dump(hidden_states, f)\n",
    "\n",
    "with open(\"assigner.pickle\", \"wb\") as f:\n",
    "    pickle.dump(assigner, f)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0491e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "with open(\"states.pickle\", \"rb\") as f:\n",
    "    states = pickle.load(f)\n",
    "\n",
    "with open(\"hidden_states.pickle\", \"rb\") as f:\n",
    "    hidden_states = pickle.load(f)\n",
    "\n",
    "with open(\"assigner.pickle\", \"rb\") as f:\n",
    "    assigner = pickle.load(f)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380041bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                        | 2/250 [00:29<1:00:51, 14.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrite_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msyndata/cor_distinct_h_transitions_noise_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massigner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_num_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_num_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_num_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 17\u001b[0m, in \u001b[0;36mwrite_dataset\u001b[0;34m(main_folder, assigner, noise, train_num_files, eval_num_files, test_num_files, n_train, n_eval, n_test)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;241m<\u001b[39m train_num_files:\n\u001b[1;32m     16\u001b[0m     df \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data\u001b[38;5;241m.\u001b[39mtrain_dataloader()):\n\u001b[1;32m     18\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     19\u001b[0m         x_d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpayload\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/rlbnb/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "write_dataset(\"syndata/cor_distinct_h_transitions_noise_0\", assigner, noise=0.,\n",
    "              train_num_files=250, eval_num_files=50, test_num_files=0,\n",
    "              n_train=256*4, n_eval=256*4, n_test=256*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724e2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_data(path):\n",
    "    train_files = ParquetFiles(os.path.join(path, \"train\"))\n",
    "    train_dataset = ParquetDataset(train_files, shuffle_files=True)\n",
    "    eval_files = ParquetFiles(os.path.join(path, \"eval\"))\n",
    "    eval_dataset = ParquetDataset(eval_files, shuffle_files=True)\n",
    "    test_files = ParquetFiles(os.path.join(path, \"test\"))\n",
    "    test_dataset = ParquetDataset(test_files, shuffle_files=True)\n",
    "    \n",
    "    sup_data = PtlsDataModule(\n",
    "        train_data=SeqToTargetIterableDataset(train_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        valid_data=SeqToTargetIterableDataset(eval_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        #test_data=SeqToTargetIterableDataset(test_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        train_batch_size=256,\n",
    "        valid_batch_size=256,\n",
    "        #test_batch_size=256,\n",
    "        train_num_workers=4,\n",
    "        valid_num_workers=4,\n",
    "        #test_num_workers=4\n",
    "    )\n",
    "    return sup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e504eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_model():\n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                #'s_feat_1': {'in': 100, 'out': 32},\n",
    "                's_feat_2': {'in': 10, 'out': 32},\n",
    "                's_feat_3': {'in': 20, 'out': 32},\n",
    "                'h_feat_1': {'in': 20, 'out': 32},\n",
    "                'h_feat_2': {'in': 10, 'out': 32},\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=128,\n",
    "        type='lstm',\n",
    "    )\n",
    "\n",
    "    sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=2),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.Accuracy(),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=1e-4),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.9),\n",
    "    )\n",
    "    return sup_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e34144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for path in [\"syndata/noise_0/\", \"syndata/noise_05/\", \"syndata/noise_1/\"]:\n",
    "for path in [\"syndata/small_noise_0/\"]:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        gpus=[0],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    \n",
    "    sup_data = get_sup_data(path)\n",
    "    sup_module = get_sup_model()\n",
    "    \n",
    "    trainer.fit(sup_module, sup_data)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "673884aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embed_model(model):\n",
    "    model.to('cuda:0')\n",
    "    \n",
    "    xx, yy = list(), list()\n",
    "    dl = iter(sup_data.train_dataloader())\n",
    "    for batch in dl:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy.append(y.numpy())\n",
    "            x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "            xx.append(x)\n",
    "\n",
    "    xx = np.concatenate(xx, axis=0)\n",
    "    yy = np.concatenate(yy, axis=0)\n",
    "    \n",
    "    xx_eval, yy_eval = list(), list()\n",
    "    dl = iter(sup_data.eval_dataloader())\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy_eval.append(y.numpy())\n",
    "            x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "            xx_eval.append(x)\n",
    "\n",
    "    xx_eval = np.concatenate(xx_eval, axis=0)\n",
    "    yy_eval = np.concatenate(yy_eval, axis=0)\n",
    "    \n",
    "    \n",
    "    xx_test, yy_test = list(), list()\n",
    "    dl = iter(sup_data.test_dataloader())\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy_test.append(y.numpy())\n",
    "            x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "            xx_test.append(x)\n",
    "\n",
    "    xx_test = np.concatenate(xx_test, axis=0)\n",
    "    yy_test = np.concatenate(yy_test, axis=0)\n",
    "    \n",
    "    \n",
    "    clf = LGBMClassifier(max_depth=-1)\n",
    "    clf.fit(xx, yy, eval_set=(xx_eval, yy_eval), eval_metric=\"auc\")\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx)[:,1]\n",
    "    train_score = roc_auc_score(yy, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_eval)[:,1]\n",
    "    eval_score = roc_auc_score(yy_eval, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict_proba(xx_test)[:,1]\n",
    "    test_score = roc_auc_score(yy_test, y_pred)\n",
    "    \n",
    "    return train_score, eval_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87997ac0",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "624065bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-04T18:12:30.244098Z",
     "iopub.status.busy": "2022-05-04T18:12:30.243491Z",
     "iopub.status.idle": "2022-05-04T18:12:30.281553Z",
     "shell.execute_reply": "2022-05-04T18:12:30.281940Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m PtlsDataModule(\n\u001b[1;32m      2\u001b[0m     train_data\u001b[38;5;241m=\u001b[39mColesDataset(\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mdataset_train\u001b[49m,\n\u001b[1;32m      4\u001b[0m         splitter\u001b[38;5;241m=\u001b[39mSampleSlices(\n\u001b[1;32m      5\u001b[0m             split_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      6\u001b[0m             cnt_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      7\u001b[0m             cnt_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      8\u001b[0m         ),\n\u001b[1;32m      9\u001b[0m     ),\n\u001b[1;32m     10\u001b[0m     valid_data\u001b[38;5;241m=\u001b[39mColesDataset(\n\u001b[1;32m     11\u001b[0m         dataset_valid,\n\u001b[1;32m     12\u001b[0m         splitter\u001b[38;5;241m=\u001b[39mSampleSlices(\n\u001b[1;32m     13\u001b[0m             split_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     14\u001b[0m             cnt_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     15\u001b[0m             cnt_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,),\n\u001b[1;32m     16\u001b[0m     ),\n\u001b[1;32m     17\u001b[0m     train_num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     18\u001b[0m     train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     19\u001b[0m     valid_num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     20\u001b[0m     valid_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        dataset_train,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=20,\n",
    "            cnt_max=50,\n",
    "        ),\n",
    "    ),\n",
    "    valid_data=ColesDataset(\n",
    "        dataset_valid,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=20,\n",
    "            cnt_max=50,),\n",
    "    ),\n",
    "    train_num_workers=16,\n",
    "    train_batch_size=256,\n",
    "    valid_num_workers=16,\n",
    "    valid_batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6ee58",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "988c508d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-04T18:12:30.169403Z",
     "iopub.status.busy": "2022-05-04T18:12:30.168916Z",
     "iopub.status.idle": "2022-05-04T18:12:30.240250Z",
     "shell.execute_reply": "2022-05-04T18:12:30.239734Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            #'s_feat_1': {'in': 100, 'out': 32},\n",
    "            's_feat_2': {'in': 16, 'out': 32},\n",
    "            's_feat_3': {'in': 32, 'out': 32},\n",
    "            'h_feat_1': {'in': 32, 'out': 32},\n",
    "            'h_feat_2': {'in': 16, 'out': 32},\n",
    "        },\n",
    "        embeddings_noise=0.001,\n",
    "    ),\n",
    "    hidden_size=128,\n",
    "    type='lstm'\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fdbb67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-04T18:12:30.285432Z",
     "iopub.status.busy": "2022-05-04T18:12:30.284949Z",
     "iopub.status.idle": "2022-05-04T18:12:30.325745Z",
     "shell.execute_reply": "2022-05-04T18:12:30.325312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 134 K \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "134 K     Trainable params\n",
      "0         Non-trainable params\n",
      "134 K     Total params\n",
      "0.537     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=[0],\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "trainer.fit(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40877df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-04T18:12:30.328969Z",
     "iopub.status.busy": "2022-05-04T18:12:30.328486Z",
     "iopub.status.idle": "2022-05-04T18:23:09.969669Z",
     "shell.execute_reply": "2022-05-04T18:23:09.969186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0531), 'seq_len': tensor(33.7000), 'recall_top_k': tensor(0.2499)}\n"
     ]
    }
   ],
   "source": [
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d82f71b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoLESModule(\n",
       "  (_loss): ContrastiveLoss()\n",
       "  (_seq_encoder): RnnSeqEncoder(\n",
       "    (trx_encoder): TrxEncoder(\n",
       "      (embeddings): ModuleDict(\n",
       "        (s_feat_2): NoisyEmbedding(\n",
       "          10, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (s_feat_3): NoisyEmbedding(\n",
       "          20, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (h_feat_1): NoisyEmbedding(\n",
       "          20, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (h_feat_2): NoisyEmbedding(\n",
       "          10, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (custom_embeddings): ModuleDict()\n",
       "    )\n",
       "    (seq_encoder): RnnEncoder(\n",
       "      (rnn): LSTM(128, 128, batch_first=True)\n",
       "      (reducer): LastStepEncoder()\n",
       "    )\n",
       "  )\n",
       "  (_validation_metric): BatchRecallTopK()\n",
       "  (_head): Head(\n",
       "    (model): Sequential(\n",
       "      (0): L2NormEncoder()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9be9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.69it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.70it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.59it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.66it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.74it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.71it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.67it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.51it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.70it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.64it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:11<00:00,  6.88it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.57it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.54it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.63it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.52it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.62it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.58it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.42it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.36it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "xx, yy = list(), list()\n",
    "\n",
    "for i in range(20):\n",
    "    dl = iter(sup_data.train_dataloader())\n",
    "    for batch in tqdm(dl):\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy.append(y.numpy())\n",
    "            x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "            xx.append(x)\n",
    "\n",
    "xx = np.concatenate(xx, axis=0)\n",
    "yy = np.concatenate(yy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35b5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 79/79 [00:10<00:00,  7.74it/s]\n"
     ]
    }
   ],
   "source": [
    "xx_test, yy_test = list(), list()\n",
    "dl = iter(sup_data.test_dataloader())\n",
    "for batch in tqdm(dl):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        yy_test.append(y.numpy())\n",
    "        x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "        xx_test.append(x)\n",
    "\n",
    "xx_test = np.concatenate(xx_test, axis=0)\n",
    "yy_test = np.concatenate(yy_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83640fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 100000, number of negative: 100000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(max_depth=-1)\n",
    "clf.fit(xx, yy, eval_set=(xx_test, yy_test), eval_metric=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "441d5ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5959359200000001"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(xx_test)[:,1]\n",
    "roc_auc_score(yy_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d7eaa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6708364566"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(xx)[:,1]\n",
    "roc_auc_score(yy, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f823cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hmm = partial(HMM, states=states, hidden_states=hidden_states,\n",
    "                  hidden_state_transition_matrix=hidden_state_transition_matrix, noise=1.)\n",
    "\n",
    "train_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[:5000])\n",
    "train_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[:5000])\n",
    "\n",
    "valid_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[5000:7000])\n",
    "valid_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[5000:7000])\n",
    "\n",
    "test_pos_hmms = get_hmm(state_transition_tensors=pos_tensors[7000:])\n",
    "test_neg_hmms = get_hmm(state_transition_tensors=neg_tensors[7000:])\n",
    "\n",
    "\n",
    "\n",
    "dataset_train = SyntheticDataset([train_pos_hmms, train_neg_hmms], seq_len=200)\n",
    "dataset_valid = SyntheticDataset([valid_pos_hmms, valid_neg_hmms], seq_len=200)\n",
    "dataset_test = SyntheticDataset([test_pos_hmms, test_neg_hmms], seq_len=200)\n",
    "\n",
    "\n",
    "\n",
    "sup_data = PtlsDataModule(\n",
    "    train_data=SeqToTargetDataset(dataset_train, target_col_name='class_label', target_dtype=torch.long),\n",
    "    valid_data=SeqToTargetDataset(dataset_valid, target_col_name='class_label', target_dtype=torch.long),\n",
    "    test_data=SeqToTargetDataset(dataset_test, target_col_name='class_label', target_dtype=torch.long),\n",
    "    train_batch_size=128,\n",
    "    valid_batch_size=256,\n",
    "    train_num_workers=16,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        dataset_train,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=20,\n",
    "            cnt_max=50,\n",
    "        ),\n",
    "    ),\n",
    "    valid_data=ColesDataset(\n",
    "        dataset_valid,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=20,\n",
    "            cnt_max=50,),\n",
    "    ),\n",
    "    train_num_workers=16,\n",
    "    train_batch_size=256,\n",
    "    valid_num_workers=16,\n",
    "    valid_batch_size=256,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            #'s_feat_1': {'in': 100, 'out': 32},\n",
    "            's_feat_2': {'in': 10, 'out': 32},\n",
    "            's_feat_3': {'in': 20, 'out': 32},\n",
    "            'h_feat_1': {'in': 20, 'out': 32},\n",
    "            'h_feat_2': {'in': 10, 'out': 32},\n",
    "        },\n",
    "        embeddings_noise=0.001,\n",
    "    ),\n",
    "    hidden_size=128,\n",
    "    type='lstm'\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa3fc8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 134 K \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "134 K     Trainable params\n",
      "0         Non-trainable params\n",
      "134 K     Total params\n",
      "0.537     Total estimated model params size (MB)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "        self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in:         <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      ": \n",
      "        can only test a child processTraceback (most recent call last):\n",
      "self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "\n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "AssertionErrorself._shutdown_workers()    : \n",
      "if w.is_alive():can only test a child process  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>if w.is_alive():Exception ignored in:     \n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "AssertionError    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      ": self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>Exception ignored in: \n",
      "can only test a child process    \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "AssertionError\n",
      "self._shutdown_workers()  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "\n",
      ": \n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "can only test a child processTraceback (most recent call last):\n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "if w.is_alive():    self._shutdown_workers()\n",
      "    if w.is_alive():\n",
      "self._shutdown_workers()  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "Exception ignored in: \n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "        <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>AssertionError\n",
      "AssertionError  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    :   File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'        can only test a child process    Traceback (most recent call last):\n",
      "can only test a child process\n",
      "self._shutdown_workers()self._shutdown_workers()\n",
      "Exception ignored in: Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "AssertionErrorException ignored in: \n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>:       File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "AssertionError\n",
      "can only test a child process\n",
      "\n",
      "self._shutdown_workers()    :     \n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: Exception ignored in: if w.is_alive():can only test a child processif w.is_alive():Exception ignored in:   File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>            \n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()self._shutdown_workers()if w.is_alive():Traceback (most recent call last):\n",
      "    Exception ignored in: Traceback (most recent call last):\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "    \n",
      "\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "          File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    \n",
      "\n",
      "        AssertionError    self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()    Traceback (most recent call last):\n",
      "AssertionErrorif w.is_alive():: assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "\n",
      "if w.is_alive():  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      ": can only test a child process\n",
      "\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "can only test a child process  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "AssertionError  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "        : self._shutdown_workers()    if w.is_alive():if w.is_alive():if w.is_alive():    assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child processException ignored in: \n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "Exception ignored in: AssertionError  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "        AssertionErrorAssertionError: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>    Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    : if w.is_alive():: \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child processcan only test a child process\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "\n",
      "AssertionError    \n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "AssertionErrorAssertionErrorself._shutdown_workers():     :     : \n",
      "can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()can only test a child processcan only test a child process  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AssertionError      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "Exception ignored in: Exception ignored in: : if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>can only test a child processException ignored in: \n",
      "\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "    Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: \n",
      "      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers(): \n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "\n",
      "can only test a child processTraceback (most recent call last):\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      ":   File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "            can only test a child process    if w.is_alive():    if w.is_alive():self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "self._shutdown_workers()\n",
      "\n",
      "\n",
      "Exception ignored in:   File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Traceback (most recent call last):\n",
      "if w.is_alive():\n",
      "\n",
      "AssertionError\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError: AssertionError      File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    : can only test a child process: self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child processcan only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "AssertionErrorAssertionError:     : can only test a child processcan only test a child process\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "AssertionError:     can only test a child processself._shutdown_workers()\n",
      "\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9ec5f1b0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=[0],\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "trainer.fit(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b1afb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0529), 'seq_len': tensor(34.5125), 'recall_top_k': tensor(0.2531)}\n"
     ]
    }
   ],
   "source": [
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8253a74a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoLESModule(\n",
       "  (_loss): ContrastiveLoss()\n",
       "  (_seq_encoder): RnnSeqEncoder(\n",
       "    (trx_encoder): TrxEncoder(\n",
       "      (embeddings): ModuleDict(\n",
       "        (s_feat_2): NoisyEmbedding(\n",
       "          10, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (s_feat_3): NoisyEmbedding(\n",
       "          20, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (h_feat_1): NoisyEmbedding(\n",
       "          20, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (h_feat_2): NoisyEmbedding(\n",
       "          10, 32, padding_idx=0\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (custom_embeddings): ModuleDict()\n",
       "    )\n",
       "    (seq_encoder): RnnEncoder(\n",
       "      (rnn): LSTM(128, 128, batch_first=True)\n",
       "      (reducer): LastStepEncoder()\n",
       "    )\n",
       "  )\n",
       "  (_validation_metric): BatchRecallTopK()\n",
       "  (_head): Head(\n",
       "    (model): Sequential(\n",
       "      (0): L2NormEncoder()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "918adca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.28it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.37it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.33it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.41it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.19it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.44it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.22it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.37it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.26it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.30it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.39it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.36it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.32it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.36it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.28it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.27it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.28it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.25it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.29it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "xx, yy = list(), list()\n",
    "\n",
    "for i in range(20):\n",
    "    dl = iter(sup_data.train_dataloader())\n",
    "    for batch in tqdm(dl):\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            yy.append(y.numpy())\n",
    "            x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "            xx.append(x)\n",
    "\n",
    "xx = np.concatenate(xx, axis=0)\n",
    "yy = np.concatenate(yy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d62ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 79/79 [00:12<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "xx_test, yy_test = list(), list()\n",
    "dl = iter(sup_data.train_dataloader())\n",
    "for batch in tqdm(dl):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        yy_test.append(y.numpy())\n",
    "        x = model(x.to('cuda:0')).detach().cpu().numpy()\n",
    "        xx_test.append(x)\n",
    "\n",
    "xx_test = np.concatenate(xx_test, axis=0)\n",
    "yy_test = np.concatenate(yy_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bdacaa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 100000, number of negative: 100000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LGBMClassifier(max_depth=-1)\n",
    "clf.fit(xx, yy, eval_set=(xx_test, yy_test), eval_metric=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41e73656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5920572000000001"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(xx_test)[:,1]\n",
    "roc_auc_score(yy_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "378770bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6710661666"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(xx)[:,1]\n",
    "roc_auc_score(yy, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa83996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55487161, 0.06509573, 0.00810829, 0.37192438])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(4)\n",
    "a = a / np.sqrt((a**2).sum()) * 4\n",
    "a = np.exp(a) / np.exp(a).sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0932a84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4]),\n",
       " array([5, 6, 7, 8, 9]),\n",
       " array([10, 11, 12, 13, 14]),\n",
       " array([15, 16, 17, 18, 19]),\n",
       " array([20, 21, 22, 23, 24])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.arange(25).reshape(5,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e153ad723e521bdc1aff37b3bab9b1f3df31355f5a727a9b9eb7d0282ae9ca8c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ee6696e36a496fb14601e1c68db4d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "0ca97f55cd3d4437a1b1b074c908c230": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26137948bd8f45429b7893dc09a75069": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26952339137e436eb5ce6961037effbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "364d6da46fa8437c996fd4f255f72698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37640538cd7c42989bfe6f34813a9319": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "489653f34e424b4a8d1693feac4301bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e33f33225f004815ae295a2b9f453883",
       "placeholder": "​",
       "style": "IPY_MODEL_26952339137e436eb5ce6961037effbe",
       "value": "Epoch 14: 100%"
      }
     },
     "60c687724a2a4c9a80a1a58c7a218bbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "621f6072336e40618ab6adae38e1e762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "70b148cd72e145038118fea79ff32c54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8afe3d3475684582a8d0e8b673fcad49",
       "placeholder": "​",
       "style": "IPY_MODEL_748d27490e9148219c8f188194a8b604",
       "value": "Predicting: "
      }
     },
     "71469a60dd8e4b74a97eb7c27e3aaa4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a080e7d5d5d5454aaa5aec47ab11b2f7",
        "IPY_MODEL_e79e92771c444f9fabb37c2dc304aafc",
        "IPY_MODEL_93d164c36d7146058ae0b9d8d475b06d"
       ],
       "layout": "IPY_MODEL_8831196896a64181b02a5ad0d22e0dd8"
      }
     },
     "748d27490e9148219c8f188194a8b604": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7c9829f7a9b847fdb5aeadf917a8fd7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "84559c5ef59c4ec68695403555d74c81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70b148cd72e145038118fea79ff32c54",
        "IPY_MODEL_8ccfd768f9ec462186047f88089f9a01",
        "IPY_MODEL_f4559629cb4e4f22b2cb2b1a4198c374"
       ],
       "layout": "IPY_MODEL_01ee6696e36a496fb14601e1c68db4d7"
      }
     },
     "8831196896a64181b02a5ad0d22e0dd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "8afe3d3475684582a8d0e8b673fcad49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ccfd768f9ec462186047f88089f9a01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9bab642e75ac41e29b049d13299c709c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_caa6bc12efc24d27b2a589f722bb8dcd",
       "value": 1
      }
     },
     "93d164c36d7146058ae0b9d8d475b06d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fba40d205bf7433baad90f9e567710e8",
       "placeholder": "​",
       "style": "IPY_MODEL_621f6072336e40618ab6adae38e1e762",
       "value": " 118/? [00:03&lt;00:00,  6.30it/s]"
      }
     },
     "9bab642e75ac41e29b049d13299c709c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a080e7d5d5d5454aaa5aec47ab11b2f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ca97f55cd3d4437a1b1b074c908c230",
       "placeholder": "​",
       "style": "IPY_MODEL_7c9829f7a9b847fdb5aeadf917a8fd7f",
       "value": "Predicting: "
      }
     },
     "aacec0ffb61e47c188f42f5d4ee93d07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_489653f34e424b4a8d1693feac4301bd",
        "IPY_MODEL_cc2169b121624ce490b28642b260ee68",
        "IPY_MODEL_de9674f610a04a50a662d37cd7a0fe98"
       ],
       "layout": "IPY_MODEL_60c687724a2a4c9a80a1a58c7a218bbc"
      }
     },
     "b26ad2fd0b2245d899312ce0ebd50f40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c1353e5ca7c64b2183ce2533b240acd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c9ded1ea494a476cbc5286e310d9a989": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "caa6bc12efc24d27b2a589f722bb8dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc2169b121624ce490b28642b260ee68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc7588a078fe43a2a0838cbee8349163",
       "max": 94,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b26ad2fd0b2245d899312ce0ebd50f40",
       "value": 94
      }
     },
     "cc7588a078fe43a2a0838cbee8349163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de9674f610a04a50a662d37cd7a0fe98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_37640538cd7c42989bfe6f34813a9319",
       "placeholder": "​",
       "style": "IPY_MODEL_c1353e5ca7c64b2183ce2533b240acd4",
       "value": " 94/94 [00:44&lt;00:00,  2.10it/s, loss=373, v_num=9, seq_len=113.0]"
      }
     },
     "e33f33225f004815ae295a2b9f453883": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e79e92771c444f9fabb37c2dc304aafc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9ded1ea494a476cbc5286e310d9a989",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_364d6da46fa8437c996fd4f255f72698",
       "value": 1
      }
     },
     "ecea7cc60e854a51bb8d5b1498235515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4559629cb4e4f22b2cb2b1a4198c374": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecea7cc60e854a51bb8d5b1498235515",
       "placeholder": "​",
       "style": "IPY_MODEL_26137948bd8f45429b7893dc09a75069",
       "value": " 188/? [00:15&lt;00:00,  6.24it/s]"
      }
     },
     "fba40d205bf7433baad90f9e567710e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
